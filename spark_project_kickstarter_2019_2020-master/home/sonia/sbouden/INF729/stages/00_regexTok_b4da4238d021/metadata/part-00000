{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1573833199627,"sparkVersion":"2.3.4","uid":"regexTok_b4da4238d021","paramMap":{"minTokenLength":1,"outputCol":"tokens","toLowercase":true,"gaps":true,"pattern":"\\W+","inputCol":"text"}}
